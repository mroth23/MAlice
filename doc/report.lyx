#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.8cm
\topmargin 2.8cm
\rightmargin 2.8cm
\bottommargin 2.8cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
The compiler
\end_layout

\begin_layout Subsection
Parser choice
\end_layout

\begin_layout Standard
We chose the 
\emph on
parsec 
\emph default
library to do scanning and parsing in our compiler.
 Parsec is a monadic parser combinator library for LL grammars with optional,
 infinite lookahead.
 In 
\emph on
parsec
\emph default
, grammar rules are written down in Haskell in a similar form to BNF.
 They can then be combined with combinators to form more complex parsers,
 e.g.
 choice can be made between different rules where the first succeeding rule
 produces the result, or a parser can be applied many times, generating
 a list of results.
 In our eyes, this has several advantages over separately written or generated
 parser-scanner pairs.
\begin_inset Newline newline
\end_inset

Firstly, there is no real need
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Although it is possible to write a separate lexer with parsec
\end_layout

\end_inset

 to write or generate a scanner, since the library already allows to specify
 reserved words, operators, comments and other bits that would form lexemes.
 Challenges with interfacing the scanner and parser are practically eliminated.
\begin_inset Newline newline
\end_inset

Secondly, the whole parser/scanner unit is written and embedded in the language
 of the rest of the compiler (Haskell).
 This allows subtle fine-tuning of the parsing process, and gives access
 to the powerful type system and other facilities of Haskell.
 In particular, 
\emph on
parsec 
\emph default
is not just monadic, it is also a monad transformer, which allows arbitrary
 monads to be naturally integrated with it.
 In theory, this would allow the parser to read for example imported files
 through the IO monad, or have other side effects.
 Since our implementation is rather straight-forward, we use the default
 
\emph on
ParsecT
\emph default
 that is strapped to the identity monad.
 We do however use a custom parser state to perform static checking in the
 parsing stage.
 A log of errors and warnings is kept so the parser doesn't have to terminate
 when a semantic error occurs.
 There is also a symbol table to keep track of scope, and location storage
 for better, more precise error output.
\begin_inset Newline newline
\end_inset

While there are generally concerns about performance in parser combinator
 libraries, parsec has been designed to be 
\begin_inset Quotes eld
\end_inset


\emph on
industrial strength
\begin_inset Quotes erd
\end_inset


\emph default
.
 We believe that with some careful design of the grammar, ensuring it is
 as predictive (LL(1)) as possible, there need to be no concerns about this.
 Our parser only uses look-ahead in very few places, and our tests have
 shown that it can parse large MAlice files of thousands of lines of code
 in the blink of an eye
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Parsed, type-checked, optimised and generated code for a 5.3k line MAlice
 program, with 10 levels of inner functions.
 GHC flags -O2, on a lab machine, time measured 0.22s.
\end_layout

\end_inset

.
\begin_inset Newline newline
\end_inset

Some other features of 
\emph on
parsec 
\emph default
include automatic generation of an LL expression parser through a specification
 of the precedences, associativities and expression data type in Haskell.
 It also has customisable parser error output, where messages can be attached
 to parser rules, which are displayed when parsing fails.
 Overall, this made us decide that 
\emph on
parsec
\emph default
 is a good choice to build a parser in Haskell with.
 We have also built a working parser with 
\emph on
happy
\emph default
 and 
\emph on
alex, 
\emph default
but felt that there isn't enough flexibility for keeping state and type-checking
 between the lexer and parser with that setup.
 Other, more modern parsing libraries like 
\emph on
trifecta
\emph default
 would introduce such an insane amout of dependencies
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Outside of haskell-platform, which is installed on the test machine.
\end_layout

\end_inset

 that we decided the few benefits such as slightly nicer error output wouldn't
 be worth having.
\end_layout

\begin_layout Subsection
Semantic analysis
\end_layout

\begin_layout Standard
Most of the semantic analysis in our compiler is done at the parsing stage.
 As the parser parses the program, it keeps a hierarchy of symbol tables
 for each new scope in its state.
 As new identifiers are defined, it is checked that they aren't already
 declared in the same scope.
 Next, they are added to the current symbol table together with some other
 information about them: Type, kind (variable, function, procedure), return
 type, and argument types (if any).
 On function definitions, after the function identifier has been inserted
 into the symbol table, a new scope is entered, i.e.
 a symbol table is added to the stack.
 In addition to type-checking of expressions and identifiers, every time
 a function is called, the list of arguments and return type are also checked.
\begin_inset Newline newline
\end_inset

There are some additional checks that occur after the parsing is completed.
 If the source file doesn't have the entry procedure 'hatta' defined, it
 has the wrong type signature, or is a function, an error is logged.
 If the whole parsing process completes without errors, the constructed
 abstract syntax tree is returned from the parser.
 Otherwise, a string containing the error message(s) is returned.
\end_layout

\begin_layout Subsection
Abstract syntax tree transformation
\end_layout

\begin_layout Standard
As a next step, the abstract syntax tree is modified in several passes.
 First, every nested function and identifier is renamed and given a unique
 name.
 The most important step in the transformation pass, lambda lifting, happens
 next.
 This is necessary to facilitate code generation for our JVM backend, which
 doesn't support nested methods.
 It is done in three stages: first, the abstract syntax tree is annotated
 with information about free variables in methods.
 This information is then used to modify every method call to include the
 free variables in that method as additional arguments (passed by reference),
 and every method definition is appended with the extra arguments.
 Last, there is a collection pass that walks the abstract syntax tree and
 recursively lifts all inner functions out of their original position right
 in front of their 
\begin_inset Quotes eld
\end_inset

parent
\begin_inset Quotes erd
\end_inset

 function.
\begin_inset Newline newline
\end_inset

The last part is optimisation, which is mostly done at this stage.
 Expressions are reduced as far as possible
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Optimisation for expressions: Transformation/Optimise.hs; Lambda lifting:
 Transformation/Desugar.hs; Unreachable code analysis: Transformation/Strip.hs
\end_layout

\end_inset

, and dead code such as certain control structures and functions that are
 never entered or called are removed.
 The optimised and transformed abstract syntax tree is then passed to the
 code generator.
\end_layout

\begin_layout Subsection
Code generation for the JVM
\end_layout

\begin_layout Standard
Our code generator produces bytecode assembly that can be assembled by the
 JVM assembler 
\emph on
Jasmin
\emph default
.
 The JVM can be seen as a stack machine: There are no registers, you can
 merely add and remove operands from the stack.
 This environment automatically gives us a vast array of runtime checks
 and messages, and an extensive library of classes we could tap into.
 Producing code for this system also allows us to run the same code on any
 machine that supports Java, i.e.
 our code is not platform specific.
\begin_inset Newline newline
\end_inset

The code generator explores the abstract syntax tree, recursively converting
 it into instructions.
 The instructions are then repeatedly passed over and optimisation is attempted.
 Global variables are defined as fields in the bytecode and moved to the
 top of the program.
 In producing the bytecode, there are however some major obstacles in the
 way.
\begin_inset Newline newline
\end_inset

The first problem occurs with inner functions.
 Unlike in assembly where there is complete access to the stack, in bytecode
 functions do not have such access.
 Each function has its own special stack to compute instructions and as
 its own variable storage.
 Each function may also only return one result.
 So even though we use lambda lifting for inner functions, we still had
 to find a way to allow access to read and modify the variables in the outer
 scope.
 This was achieved by using an AtomicReference object
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
As found in java.util.concurrent.atomic
\end_layout

\end_inset

.
 The AST uses a special type to indicate variables passed by reference,
 so when a function is called with the reference type primitive types would
 be wrapped into an object, to then create an AtomicReference object with
 it as its constructor parameter.
 This AtomicReference acts as a reference to the variable.
 After the function call, the atomic reference must be unwrapped, the value
 retrieved from the Object inside, and placed back into the original storage
 location.
\begin_inset Newline newline
\end_inset

Matters get even more complicated when uninitialised values have to be wrapped.
 In Java, primitives have default values and objects are created as 
\emph on
null
\emph default
.
 However in MAlice, variables can be uninitialised, which needs to be handled.
 To avoid this issue, a basic check is performed to determine if there is
 a chance the variable is unitialised and to give the AtomicReference a
 null reference if required.
 After the function call, it must then be checked if the object inside is
 null, and if not the variable can be updated as required.
 When a function is using an AtomicReference, it must retrieve the object
 inside and unwrap it to get the value, then reverse the process when storing
 a value.
\begin_inset Newline newline
\end_inset

Because of the statically typed bytecode verifier all functions must end
 with a correct return type.
 Whether or not it is possible to reach the end of a function without a
 return directly at the end, it will print an error and fail to execute.
 While it is possible to make such code execute using the 
\emph on
-noverify
\emph default
 flag, this also disables the runtime error-checking system.
 To counter this problem, we walk over the instructions and check for cases
 where this could happen.
 A call to a special function is added, and a valid return statement can
 then be added to suppress the bytecode verifier errors.
 This special function outputs an error that the function did not return
 and exits the program.
\begin_inset Newline newline
\end_inset

Global declarations of variables are packaged into a certain instruction
 that specifies them to be put into a constructor.
 All constructor instructions can then be merged together.
 In the bytecode, there will then be a main method (as required by the class),
 that calls the class constructor.
 This constructor then in turn calls the hatta function.
\begin_inset Newline newline
\end_inset

In all functions, the local stack and variable size must be defined.
 We recurse through the bytecode instructions of each function and calculate
 the maximum stack size at any point and the number of local variables required.
 When calculating the stack size, all branching is explored as it would
 be in the JVM.
\begin_inset Newline newline
\end_inset

The last thing the code generator does is to attempt to optimise the list
 of instructions.
 The first part of the optimisation is printing strings.
 IO is a very slow part of computation and so it is vital to optimise this.
 In cases where two strings are printed, one after the other, we combine
 the strings, effectively cutting the IO in half.
\begin_inset Newline newline
\end_inset

One of the most important instructions for optimisation is the 'dup' instruction
, which duplicates the top of the stack.
 If the same value was loaded onto the stack twice, it could instead be
 loaded once and then duplicated, which is much faster.
 We check for all such duplicate loads and replace them.
 During these passes, we also try to optimise printing again.
 When there are two print commands in a row, instead of constantly loading
 the System.out static class every time we try to print, these are swapped
 with 'dup's.
\begin_inset Newline newline
\end_inset

There is also an attempt to simplify conditional jumps, where binary values
 are set after condition and then another conditional jump instruction is
 requested, we try to merge the first conditional jump with the second to
 only use one conditional jump.
\begin_inset Newline newline
\end_inset

The JVM has many fast instructions for common tasks such as loading -1,
 0 or 1 onto the stack.
 For example, if the 'ldc' instruction is ever used with an immediate value,
 such as in 
\emph on
'ldc -1',
\emph default
 this would be changed to its faster alternative 
\emph on
'iconst_m1'
\emph default
.
 This optimisation can also be performed on load and store instructions
 for variables.
\begin_inset Newline newline
\end_inset

Another issue that had to be dealt with was the JVM handling characters,
 where pushing a character onto the stack converts it to an 
\emph on
int
\emph default
.
 This makes some calculations easier, however directly printing this character
 will by default print an int (the int value of the character).
 The code generator must load, store and manipulate characters as integers,
 and then if they are ever printed, request to print with the type character.
\begin_inset Newline newline
\end_inset

One of the nice features of the JVM is its run-time system.
 It automatically provides arithmetic checking and array bounds checking,
 outputting understandable errors when required.
 This is also true for stack overflows.
 We only had to implement one part of the run-time system, which was when
 a return might not reached in a function, and most other problems could
 be solved through modifications in the abstract syntax tree and careful
 instruction selection.
\end_layout

\begin_layout Section
Critical evaluation
\end_layout

\begin_layout Standard
Most importantly, our compiler follows the functional specification, with
 some extensions to the reference implementation.
 Almost all parts of the compilers are pure
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
There is no use of IO outside of file handling and library dependencies
 (parsec), except in the interactive shell.
\end_layout

\end_inset

 Haskell, and unsafe functions such as 
\emph on
head
\emph default
 and 
\emph on
fromJust
\emph default
 are avoided as much as possible unless they're certainly safe to use.
 This makes it extremely unlikely for the compiler to crash (although it
 might of course malfunction).
\begin_inset Newline newline
\end_inset

The optimisation stage is independent from code generation, so other backends
 would profit from it as well.
 Moreover, the abstract syntax tree format is annotated with some type informati
on that is retained from parsing, to accommodate for the typing needs of
 different output languages.
 This should make it relatively easy to generate other code from the front-end
 compiler we already have.
\begin_inset Newline newline
\end_inset

Since the parser is hand-written and modular, it is easy to reuse single
 bits of it, e.g.
 to parse expressions on their own.
 We have done so in the extension, our interactive MAlice shell, and written
 almost no additional code to parse user input, while generating the exact
 same data that is already used in the AST.
 This also has the benefits of getting the exact same error message system
 the parser has.
\begin_inset Newline newline
\end_inset

We believe that our compiler is designed in a way that easily allows future
 development and extensions.
 It would be trivial to add a different code generator, e.g.
 LLVM, that profits from the optimisation the compiler already does.
 The modular parser also allows adding new types or control structures very
 easily, and we have already added a boolean type to it
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Note that if control structures are added to the AST, all code that traverses
 the AST has to be amended to handle the new data constructor
\end_layout

\end_inset

.
\begin_inset Newline newline
\end_inset

Overall, development of the compiler went very well, and we wouldn't deviate
 from our chosen path too much if we had to do it again.
 One difficulty we had was the rather poor documentation available for generatin
g Java bytecode.
 Other assembly languages seem to be much more widely used in compilers
 (LLVM), or have been used to write programs for decades (Intel assembly),
 and it would have been easier to get support for these.
 While it is possible to perform more optimisations if the abstract syntax
 tree is converted to another intermediate representation, we found it easiest
 to generate code directly from the AST, since many of those optimisations
 more specifically target certain architectures, and not stack machines
 like the JVM
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
E.g.
 tail call optimisation, register selection/liveness analysis
\end_layout

\end_inset

.
\begin_inset Newline newline
\end_inset

We found that we could have profited from more extensive use of some of
 Haskell's more interesting features.
 The expression evaluator in the extension would greatly benefit from typed
 expressions (i.e.
 GADTs), but it would have been too much work to rewrite all the other code
 to change this.
\end_layout

\begin_layout Section
Beyond the specification
\end_layout

\begin_layout Standard
While we have added less important bits to the compiler, such as a boolean
 data type that can be declared in MAlice 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
dream: either 'truth' or 'lie'
\end_layout

\end_inset

 and the possibility for global variables to be assigned function call results
 at declaration, our most important extension is the MAlice interactive
 shell.
\begin_inset Newline newline
\end_inset

The idea is to provide the programmer with a tool that allows interactive
 testing of MAlice code.
 A source file can be loaded into the shell, and will be parsed and verified
 as in the normal compiler.
 However, no further optimisation is performed.
\begin_inset Newline newline
\end_inset

A user can then type arbitrary code into the shell, which will be verified
 by the type-checker and evaluated.
 Any functions and procedures from the loaded source file are available
 and can be called with arbitrary (valid) arguments.
 It is also possible to declare new variables or methods.
 All runtime state (i.e.
 global and user-defined variables) can be modified by assignment statements,
 reading values from user input, or any other statements that are supported
 in MAlice.
 Lastly, expressions can be evaluated to display their results or use them
 in further computations.
 The simulation of MAlice code is built on a stack of monads to provide
 error handling, runtime state and IO to the MAlice program, in short, a
 runtime environment is simulated.
 The evaluation will halt on encountering any errors, and produce the expected
 result otherwise.
 Any MAlice program execution can be simulated by loading it into the shell,
 and calling 
\emph on
hatta().

\emph default
 However, it is entirely possible to not follow this path and evaluate or
 test any other functions as required.
\begin_inset Newline newline
\end_inset

If any changes are made to the source file, it can be reloaded by typing
 ':r', alternatively, a new file can be loaded with ':l'.
 The interactive shell can be run with 
\emph on
./interactive /path/to/file.alice
\emph default
, and works very similar to ghci in how it is used.
\begin_inset Newline newline
\end_inset

We think that it would have been interesting to implement some of the more
 advanced optimisations, although many of them are of limited use for our
 back-end.
 As a possible further extension, it would be possible to write an LLVM
 code generator that takes full advantage of the optimisation potential
 for native code.
 Although we haven't had time to implement these features, our compiler
 architecture as a whole would provide the possibility to be extended in
 this manner.
 We believe however that we have implemented a very broad set of features
 for the specific path we've taken, which covers most of the interesting
 challenges compiler writers face.
 While it is always possible to do further optimisations (as evidenced by
 the fact that existing compilers have been improving for decades, and still
 are), this isn't necessarily feasible for a small-scale project like our
 MAlice compiler.
\end_layout

\end_body
\end_document
